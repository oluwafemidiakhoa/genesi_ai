{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "header"
   },
   "source": [
    "# üß¨ Genesis RNA: Train RNA Foundation Model in Colab\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oluwafemidiakhoa/genesi_ai/blob/main/genesis_rna/genesis_rna_colab_training.ipynb)\n",
    "\n",
    "Train a transformer-based RNA foundation model with **Adaptive Sparse Training (AST)** for energy-efficient pretraining.\n",
    "\n",
    "## Features:\n",
    "- üöÄ Free GPU training (T4/V100/A100)\n",
    "- ‚ö° Adaptive Sparse Training (60% FLOP reduction)\n",
    "- üéØ Multi-task learning (MLM + structure + pairing)\n",
    "- üìä Real-time visualization\n",
    "- üíæ Automatic checkpoint saving\n",
    "\n",
    "## Runtime Settings:\n",
    "**‚ö†Ô∏è IMPORTANT**: Go to `Runtime ‚Üí Change runtime type ‚Üí GPU (T4/V100/A100)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup"
   },
   "source": [
    "## üì¶ Step 1: Setup & Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\n‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No GPU detected! Go to Runtime ‚Üí Change runtime type ‚Üí GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "clone_repo"
   },
   "outputs": [],
   "source": [
    "# Clone repository\n",
    "!git clone https://github.com/oluwafemidiakhoa/genesi_ai.git\n",
    "%cd genesi_ai/genesis_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install_deps"
   },
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers datasets biopython pyyaml tqdm\n",
    "!pip install -q adaptive-sparse-training\n",
    "\n",
    "print(\"\\n‚úÖ All dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mount_drive"
   },
   "outputs": [],
   "source": [
    "# Optional: Mount Google Drive to save checkpoints\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create checkpoint directory in Drive\n",
    "!mkdir -p /content/drive/MyDrive/genesis_rna_checkpoints\n",
    "CHECKPOINT_DIR = \"/content/drive/MyDrive/genesis_rna_checkpoints\"\n",
    "print(f\"‚úÖ Checkpoints will be saved to: {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "data"
   },
   "source": [
    "## üìä Step 2: Data Preparation\n",
    "\n",
    "Choose one of the following options:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "option_dummy"
   },
   "source": [
    "### Option A: Quick Test with Dummy Data (Fastest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dummy_data"
   },
   "outputs": [],
   "source": [
    "# Use built-in dummy data generator\n",
    "USE_DUMMY_DATA = True\n",
    "DATA_PATH = None\n",
    "\n",
    "print(\"‚úÖ Using dummy data for quick testing\")\n",
    "print(\"   This will generate synthetic RNA sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "option_small"
   },
   "source": [
    "### Option B: Small Real Dataset (Human ncRNAs, ~5 min download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_human"
   },
   "outputs": [],
   "source": [
    "# Download human non-coding RNAs from Ensembl\n",
    "!wget -q ftp://ftp.ensembl.org/pub/current_fasta/homo_sapiens/ncrna/Homo_sapiens.GRCh38.ncrna.fa.gz\n",
    "!gunzip -f Homo_sapiens.GRCh38.ncrna.fa.gz\n",
    "\n",
    "# Preprocess\n",
    "!python scripts/preprocess_rna.py \\\n",
    "    --input Homo_sapiens.GRCh38.ncrna.fa \\\n",
    "    --output ./data/human_ncrna \\\n",
    "    --min_len 50 \\\n",
    "    --max_len 512 \\\n",
    "    --format pickle\n",
    "\n",
    "USE_DUMMY_DATA = False\n",
    "DATA_PATH = \"./data/human_ncrna\"\n",
    "\n",
    "print(\"\\n‚úÖ Human ncRNA data ready!\")\n",
    "!cat ./data/human_ncrna/stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "option_large"
   },
   "source": [
    "### Option C: Large Dataset (RNAcentral, ~30 min download, 15GB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_rnacentral"
   },
   "outputs": [],
   "source": [
    "# Download RNAcentral (WARNING: Large file!)\n",
    "!mkdir -p data/rnacentral\n",
    "!wget -c ftp://ftp.ebi.ac.uk/pub/databases/RNAcentral/current_release/sequences/rnacentral_active.fasta.gz \\\n",
    "    -O data/rnacentral/rnacentral_active.fasta.gz\n",
    "!gunzip -f data/rnacentral/rnacentral_active.fasta.gz\n",
    "\n",
    "# Preprocess (limit to 1M sequences to fit in Colab)\n",
    "!python scripts/preprocess_rna.py \\\n",
    "    --input data/rnacentral/rnacentral_active.fasta \\\n",
    "    --output ./data/rnacentral_processed \\\n",
    "    --min_len 50 \\\n",
    "    --max_len 512 \\\n",
    "    --max_sequences 1000000 \\\n",
    "    --format pickle\n",
    "\n",
    "USE_DUMMY_DATA = False\n",
    "DATA_PATH = \"./data/rnacentral_processed\"\n",
    "\n",
    "print(\"\\n‚úÖ RNAcentral data ready!\")\n",
    "!cat ./data/rnacentral_processed/stats.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "config"
   },
   "source": [
    "## ‚öôÔ∏è Step 3: Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "set_config"
   },
   "outputs": [],
   "source": [
    "# Training hyperparameters\n",
    "CONFIG = {\n",
    "    # Model size: 'small', 'base', or 'large'\n",
    "    'model_size': 'small',  # Use 'small' for Colab free tier\n",
    "    \n",
    "    # Training settings\n",
    "    'batch_size': 16,       # Adjust based on GPU memory\n",
    "    'num_epochs': 5,        # Increase for better performance\n",
    "    'learning_rate': 1e-4,\n",
    "    \n",
    "    # AST settings (energy-efficient training)\n",
    "    'use_ast': True,\n",
    "    'ast_target_activation': 0.4,  # Train on 40% of samples\n",
    "    \n",
    "    # Output\n",
    "    'output_dir': CHECKPOINT_DIR if 'CHECKPOINT_DIR' in dir() else './checkpoints',\n",
    "}\n",
    "\n",
    "print(\"üìã Training Configuration:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"   {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "train"
   },
   "source": [
    "## üöÄ Step 4: Train the Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "training_command"
   },
   "outputs": [],
   "source": "# Build training command\ncmd = f\"\"\"\npython -m genesis_rna.train_pretrain \\\n    --model_size {CONFIG['model_size']} \\\n    --batch_size {CONFIG['batch_size']} \\\n    --num_epochs {CONFIG['num_epochs']} \\\n    --learning_rate {CONFIG['learning_rate']} \\\n    --ast_target_activation {CONFIG['ast_target_activation']} \\\n    --output_dir {CONFIG['output_dir']}\n\"\"\"\n\nif USE_DUMMY_DATA:\n    cmd += \" --use_dummy_data\"\nelse:\n    cmd += f\" --data_path {DATA_PATH}\"\n\nif CONFIG['use_ast']:\n    cmd += \" --use_ast\"\n\nprint(\"üöÄ Starting training...\\n\")\nprint(f\"Command: {cmd}\\n\")\n\n# Set PYTHONPATH to include current directory so Python can find genesis_rna package\nimport os\nos.environ['PYTHONPATH'] = os.getcwd() + ':' + os.environ.get('PYTHONPATH', '')\n\n!{cmd}"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "monitor"
   },
   "source": [
    "## üìä Step 5: Monitor Training Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot_metrics"
   },
   "outputs": [],
   "source": [
    "# Visualize training metrics (if training is complete)\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check for training logs\n",
    "log_file = Path(CONFIG['output_dir']) / 'training_log.json'\n",
    "\n",
    "if log_file.exists():\n",
    "    with open(log_file) as f:\n",
    "        logs = json.load(f)\n",
    "    \n",
    "    # Plot loss curves\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Total loss\n",
    "    axes[0, 0].plot(logs['epochs'], logs['train_loss'], label='Train')\n",
    "    axes[0, 0].plot(logs['epochs'], logs['val_loss'], label='Val')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].set_title('Total Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # MLM accuracy\n",
    "    axes[0, 1].plot(logs['epochs'], logs['mlm_accuracy'])\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy')\n",
    "    axes[0, 1].set_title('MLM Accuracy')\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # AST activation rate\n",
    "    axes[1, 0].plot(logs['epochs'], logs['activation_rate'])\n",
    "    axes[1, 0].axhline(y=0.4, color='r', linestyle='--', label='Target')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Activation Rate')\n",
    "    axes[1, 0].set_title('AST Sample Selection Rate')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True)\n",
    "    \n",
    "    # Pair F1 score\n",
    "    axes[1, 1].plot(logs['epochs'], logs['pair_f1'])\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('F1 Score')\n",
    "    axes[1, 1].set_title('Base-Pair Prediction F1')\n",
    "    axes[1, 1].grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{CONFIG['output_dir']}/training_curves.png\", dpi=150)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Training metrics plotted and saved to {CONFIG['output_dir']}/training_curves.png\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training logs found yet. Run training first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## üî¨ Step 6: Test the Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "load_model"
   },
   "outputs": [],
   "source": [
    "# Load the trained model\n",
    "import sys\n",
    "sys.path.insert(0, '/content/genesi_ai/genesis_rna')\n",
    "\n",
    "import torch\n",
    "from genesis_rna.model import GenesisRNAModel\n",
    "from genesis_rna.tokenization import RNATokenizer\n",
    "\n",
    "# Load model checkpoint\n",
    "model_path = f\"{CONFIG['output_dir']}/best_model.pt\"\n",
    "model = GenesisRNAModel.from_pretrained(model_path, device='cuda')\n",
    "model.eval()\n",
    "\n",
    "# Create tokenizer\n",
    "tokenizer = RNATokenizer()\n",
    "\n",
    "print(f\"‚úÖ Model loaded from {model_path}\")\n",
    "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "predict"
   },
   "outputs": [],
   "source": [
    "# Test on example sequences\n",
    "test_sequences = [\n",
    "    \"ACGUACGUACGUACGU\",\n",
    "    \"GGCCGGCCGGCCGGCC\",\n",
    "    \"UUAAUUAAUUAAUUAA\",\n",
    "]\n",
    "\n",
    "print(\"üß¨ Testing model on example sequences:\\n\")\n",
    "\n",
    "for seq in test_sequences:\n",
    "    # Tokenize\n",
    "    input_ids = tokenizer.encode(seq, max_len=128).unsqueeze(0).to('cuda')\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids)\n",
    "    \n",
    "    # Decode MLM predictions\n",
    "    mlm_preds = outputs['mlm_logits'].argmax(dim=-1)[0]\n",
    "    predicted_seq = tokenizer.decode(mlm_preds)\n",
    "    \n",
    "    # Get structure predictions\n",
    "    struct_preds = outputs['struct_logits'].argmax(dim=-1)[0]\n",
    "    struct_labels = ['NONE', 'STEM', 'LOOP', 'BULGE', 'HAIRPIN']\n",
    "    struct_pred_str = ' '.join([struct_labels[s] for s in struct_preds[1:len(seq)+1].cpu().numpy()])\n",
    "    \n",
    "    print(f\"Input:     {seq}\")\n",
    "    print(f\"Predicted: {predicted_seq[:len(seq)]}\")\n",
    "    print(f\"Structure: {struct_pred_str}\")\n",
    "    print()\n",
    "\n",
    "print(\"‚úÖ Inference test complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "visualize"
   },
   "source": [
    "## üìä Step 7: Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "viz_attention"
   },
   "outputs": [],
   "source": [
    "# Visualize base-pair predictions\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Pick a sequence\n",
    "seq = \"GCGCAAACGCGC\"  # Simple hairpin\n",
    "input_ids = tokenizer.encode(seq, max_len=64).unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Get pair predictions\n",
    "pair_logits = outputs['pair_logits'][0].cpu().numpy()\n",
    "pair_probs = 1 / (1 + np.exp(-pair_logits))  # Sigmoid\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(pair_probs[:len(seq)+2, :len(seq)+2], cmap='Blues', interpolation='nearest')\n",
    "plt.colorbar(label='Pairing Probability')\n",
    "plt.title(f'Predicted Base-Pair Matrix\\nSequence: {seq}')\n",
    "plt.xlabel('Position')\n",
    "plt.ylabel('Position')\n",
    "\n",
    "# Add sequence labels\n",
    "labels = ['[CLS]'] + list(seq) + ['[SEP]']\n",
    "plt.xticks(range(len(seq)+2), labels, rotation=90)\n",
    "plt.yticks(range(len(seq)+2), labels)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Base-pair prediction heatmap generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "download"
   },
   "source": [
    "## üíæ Step 8: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "download_checkpoint"
   },
   "outputs": [],
   "source": [
    "# Zip checkpoint directory\n",
    "!zip -r genesis_rna_model.zip {CONFIG['output_dir']}\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download('genesis_rna_model.zip')\n",
    "\n",
    "print(\"‚úÖ Model checkpoint downloaded as genesis_rna_model.zip\")\n",
    "print(\"\\nüìÅ Checkpoint contents:\")\n",
    "!ls -lh {CONFIG['output_dir']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "next_steps"
   },
   "source": [
    "## üéØ Next Steps\n",
    "\n",
    "### Continue Training\n",
    "- Increase `num_epochs` for better performance\n",
    "- Try `model_size='base'` for higher capacity (if you have Colab Pro)\n",
    "- Use RNAcentral for full-scale pretraining\n",
    "\n",
    "### Fine-Tuning\n",
    "- Mutation effect prediction\n",
    "- RNA-protein binding\n",
    "- mRNA optimization\n",
    "\n",
    "### Evaluation\n",
    "- Test on benchmark datasets\n",
    "- Compare with RiNALMo/RNA-FM\n",
    "- Ablation studies (with/without AST)\n",
    "\n",
    "### Deploy\n",
    "- Export to ONNX for inference\n",
    "- Build REST API\n",
    "- Create web interface\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub**: https://github.com/oluwafemidiakhoa/genesi_ai\n",
    "- **Documentation**: `genesis_rna/claude/genesis_rna_design_doc.md`\n",
    "- **Paper**: (Link to your paper when published)\n",
    "\n",
    "---\n",
    "\n",
    "**Built with ‚ù§Ô∏è for RNA research | Powered by Adaptive Sparse Training**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}