{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ Genesis RNA - Quick Start (5 Minutes)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/oluwafemidiakhoa/genesi_ai/blob/main/genesis_rna/genesis_rna_quick_start.ipynb)\n",
    "\n",
    "Train a small RNA foundation model with dummy data in under 5 minutes!\n",
    "\n",
    "**‚ö†Ô∏è Enable GPU**: Runtime ‚Üí Change runtime type ‚Üí T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Clone repo\n",
    "!git clone -q https://github.com/oluwafemidiakhoa/genesi_ai.git\n",
    "%cd genesi_ai/genesis_rna\n",
    "\n",
    "# 2. Install dependencies\n",
    "!pip install -q transformers datasets biopython pyyaml adaptive-sparse-training\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 3. Train small model with dummy data (2-3 minutes)\n# Set PYTHONPATH to include current directory so Python can find genesis_rna package\nimport os\nos.environ['PYTHONPATH'] = os.getcwd() + ':' + os.environ.get('PYTHONPATH', '')\n\n!python -m genesis_rna.train_pretrain \\\n    --use_dummy_data \\\n    --model_size small \\\n    --batch_size 16 \\\n    --num_epochs 3 \\\n    --use_ast \\\n    --output_dir ./checkpoints"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Test the model\n",
    "import sys\n",
    "sys.path.insert(0, '/content/genesi_ai/genesis_rna')\n",
    "\n",
    "import torch\n",
    "from genesis_rna.model import GenesisRNAModel\n",
    "from genesis_rna.tokenization import RNATokenizer\n",
    "\n",
    "# Load model\n",
    "model = GenesisRNAModel.from_pretrained('./checkpoints/best_model.pt', device='cuda')\n",
    "tokenizer = RNATokenizer()\n",
    "model.eval()\n",
    "\n",
    "# Test sequence\n",
    "seq = \"ACGUACGUACGU\"\n",
    "input_ids = tokenizer.encode(seq, max_len=64).unsqueeze(0).to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "print(f\"‚úÖ Model inference successful!\")\n",
    "print(f\"   Input: {seq}\")\n",
    "print(f\"   Output shape: {outputs['mlm_logits'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Success!\n",
    "\n",
    "You've trained your first RNA foundation model!\n",
    "\n",
    "### Next Steps:\n",
    "1. **Use real data**: See `genesis_rna_colab_training.ipynb` for full training\n",
    "2. **Increase model size**: Try `--model_size base`\n",
    "3. **Train longer**: Increase `--num_epochs`\n",
    "\n",
    "### Full Tutorial:\n",
    "üìì [genesis_rna_colab_training.ipynb](https://colab.research.google.com/github/oluwafemidiakhoa/genesi_ai/blob/main/genesis_rna/genesis_rna_colab_training.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}